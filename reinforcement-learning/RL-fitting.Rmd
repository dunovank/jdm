---
title: "RL-fitting"
author: "Russ Poldrack"
date: "March 6, 2016"
output: html_document
runtime: shiny
---

This notebook provides an example of how to fit a simple reinforcement learning model to a dataset. For an excellent guide to how to fit reinforcement learning models to data, please have a look at [http://www.princeton.edu/~ndaw/d10.pdf]

*NOTE*: The notebook will sit idle for a little while after starting and after any change of parameters, because estimation of the likelihood surface is fairly slow.

```{r, echo=FALSE,warnings=FALSE,message=FALSE}
source('RL-helpers.R')
```



```{r, echo=FALSE}
inputPanel(
  sliderInput("pA", label = "p(reward|correct)",
              min = 0.5, max = 1, value = 0.8, step = 0.1),
  sliderInput("learning_rate", label = "Learning rate",
              min = 0.001, max = 0.25, value = 0.1, step = 0.001),
  sliderInput("temperature", label = "Softmax inverse temperature",
              min = 0.1, max = 20.1, value = 10., step = 0.1)
)

dataInput <- reactive({
  g=generate_data(input$learning_rate,input$temperature,input$pA)
  return(g)
})

renderPlot({
  g=dataInput()
  par(mfrow=c(2,2))
  plot(get_correct_resp(),type='l',ylab='Proportion responses')
  l=loess(y~x,span=0.1,data.frame(y=g$resp,x=seq(length(g$resp))))
  lines(predict(l,seq(length(g$resp))),col='blue')
  plot(g$q[,1],col='red',type='l',ylab='Q-values')
  lines(g$q[,2],col='blue')
  ll=get_ll_surface(g)
  loglike=-1*ll$ll
  image(ll$lrvals,ll$tempvals,loglike,xlab='learning rate',ylab='inverse temperature')
  contour(ll$lrvals,ll$tempvals,loglike,add=TRUE)
  mincoords=which(loglike==max(loglike),arr.ind=TRUE)
  points(ll$lrvals[mincoords[1]],ll$tempvals[mincoords[2]],pch=18,col='black')
  mlest=nlm(q_negloglike,p=c(0.0001,0.0001),g=dataInput())
  title(sprintf('MLE: LR = %0.3f, beta = %0.3f',mlest$estimate[1],mlest$estimate[2]))
  })


```
